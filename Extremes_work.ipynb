{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atkinsonde/524/blob/main/Extremes_work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb0P7qMDyU2i"
      },
      "source": [
        "<h4>additional resouce sites</h4>\n",
        "\n",
        "https://www.ndsu.edu/pubweb/~sainieid/group/100-year.htm\n",
        "\n",
        "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rank.html\n",
        "\n",
        "https://data.library.virginia.edu/understanding-q-q-plots/\n",
        "\n",
        "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html#scipy.stats.linregress\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/atkinsonde/524.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP3XK0aIyoIX",
        "outputId": "d4a08b61-5bad-47db-b77e-633294ddd0a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '524'...\n",
            "remote: Enumerating objects: 117, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 117 (delta 8), reused 0 (delta 0), pack-reused 83\u001b[K\n",
            "Receiving objects: 100% (117/117), 5.67 MiB | 14.06 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MAoDqe_cyU2q"
      },
      "outputs": [],
      "source": [
        "# load all of the reqired libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from scipy import stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hwum7qq8yU2s"
      },
      "outputs": [],
      "source": [
        "# import source data\n",
        "df = pd.read_csv('/content/524/extremes/08LE021_Daily_Flow_ts.csv',\n",
        "            parse_dates = ['Date'],\n",
        "            usecols=['PARAM','Date','Flow']\n",
        "            ) \n",
        "\n",
        "df = df.set_index('Date')\n",
        "\n",
        "df.sort_index(inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "btpwJvZfyU2t"
      },
      "outputs": [],
      "source": [
        "# restucture dataset for application\n",
        "df1 = df['Flow'][df['PARAM']==1]\n",
        "\n",
        "# here we are grouping our values by year and only using the max value in a given year\n",
        "df1_max = df1.groupby(df1.index.year).max()\n",
        "\n",
        "df1_sub = pd.DataFrame(df1_max)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YkX_rQGyU2u"
      },
      "outputs": [],
      "source": [
        "# generate qq plots for context and data exploration and visualization\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "\n",
        "qqplot_data = qqplot(df1_sub.Value, line='s').gca().lines\n",
        "\n",
        "qqplot_data = qqplot(df1_sub.Value, \n",
        "                     dist=stats.gamma,\n",
        "                     distargs=([1]),\n",
        "                     line='r').gca().lines\n",
        "\n",
        "qqplot_data = qqplot(df1_sub.Value[df1_sub.Value<3000], \n",
        "                     dist=stats.gamma,\n",
        "                     distargs=([1]),\n",
        "                     line='r').gca().lines\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6v888QAqyU2v"
      },
      "outputs": [],
      "source": [
        "# plotly version of the plot above\n",
        "fig = go.Figure([\n",
        "        go.Scatter(      \n",
        "            x=qqplot_data[0].get_xdata(), y=qqplot_data[0].get_ydata(),\n",
        "            mode='markers',opacity=0.65,line=dict(color='blue', width=2),\n",
        "            name='data'\n",
        "            ),\n",
        "        go.Scatter(      \n",
        "            x=qqplot_data[1].get_xdata(), y=qqplot_data[1].get_ydata(),\n",
        "            mode='lines',line=dict(color='red', width=2),\n",
        "            name='qq'\n",
        "            )\n",
        "        ])\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptNyUcCtyU2x"
      },
      "source": [
        "<h6>next step is to calculate return interval for our dataset</h6>\n",
        "\n",
        "For each data point, a Recurrence Interval (RI) is calculated using the Weibull equation\n",
        "\n",
        "RI = (n+1)/m\n",
        "\n",
        "the peak discharges are ranked from m = 1 (largest), m = 2 (second largest) and so on to m=n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyNNJ4_4yU2y"
      },
      "outputs": [],
      "source": [
        "# first get n value using the length function on our dataframe\n",
        "n = len(df1_sub)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYOtfpDTyU20"
      },
      "outputs": [],
      "source": [
        "# next we create a column with a rank for our values\n",
        "df1_sub['ranked'] = df1_sub['Value'].rank(ascending=False ,method='first')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4R_-FOZtyU24"
      },
      "outputs": [],
      "source": [
        "# once we have our n and m values we can create a column with RI's for our values\n",
        "df1_sub['RI'] = (n + 1)/df1_sub['ranked']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXIhguGHyU25"
      },
      "outputs": [],
      "source": [
        "# now we have all our data organized let's plot it!\n",
        "Y = np.array(df1_sub['Value'])\n",
        "X = np.array(df1_sub.RI)\n",
        "\n",
        "linear_res = stats.linregress(np.log(X), Y)\n",
        "linear_res_y = linear_res.intercept + linear_res.slope * np.log(X)\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(mode=\"markers\", x=df1_sub.RI, y=df1_sub[\"Value\"]))\n",
        "\n",
        "fig.add_trace(go.Scatter(mode=\"lines\", x=df1_sub.RI, y=linear_res_y))\n",
        "\n",
        "fig.update_xaxes(type=\"log\",range=[0,2])\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-gyuBdqyU26"
      },
      "outputs": [],
      "source": [
        "# now we have our linear regression set let's make some predictions\n",
        "\n",
        "# discharge prediction\n",
        "year_return = 100\n",
        "predict_value = linear_res.intercept + linear_res.slope * np.log(year_return)\n",
        "\n",
        "print('full dataset predicted discharge for 1/{} years equals {:.0f} m^3/s'.format(year_return,predict_value))\n",
        "\n",
        "# year prediction\n",
        "future_value = 2000\n",
        "predict_year = np.exp((future_value - linear_res.intercept)/linear_res.slope)\n",
        "\n",
        "print('full dataset predicted discharge for 1/{:.0f} years equals {} m^3/s'.format(predict_year,future_value))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXyqEhMkyU26"
      },
      "source": [
        "<h3>after reviewing the plots above it is clear that it is probably best to revome the extreme outlier value from our data and regenerate our linear regression calculation</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHvvGTfSyU27"
      },
      "outputs": [],
      "source": [
        "# trim the dataset to only include values under 3000\n",
        "data = pd.DataFrame(df1_max)\n",
        "data = data[data.Value < 3000]\n",
        "#df1_sub = df1_sub.sort_values(by='ranked')\n",
        "\n",
        "# as we did above let's recalculate our RI's\n",
        "n = len(data)\n",
        "data['ranked'] = data['Value'].rank(ascending=False ,method='first')\n",
        "data['RI'] = (n + 1)/data['ranked']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeuMK2qfyU28"
      },
      "outputs": [],
      "source": [
        "# now we have removed the extreme outlier let's re-plot it!\n",
        "Y = np.array(data['Value'])\n",
        "X = np.array(data.RI)\n",
        "\n",
        "linear_res = stats.linregress(np.log(X), Y)\n",
        "linear_res_y = linear_res.intercept + linear_res.slope * np.log(X)\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(mode=\"markers\", x=data.RI, y=data[\"Value\"]))\n",
        "\n",
        "fig.add_trace(go.Scatter(mode=\"lines\", x=data.RI, y=linear_res_y))\n",
        "\n",
        "fig.update_xaxes(type=\"log\",range=[0,2])\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l6DjkE3yU28"
      },
      "outputs": [],
      "source": [
        "# now we have removed the extreme outlier from our dataset and \n",
        "# recalculated our linear regression set let's redo our predictions\n",
        "\n",
        "# discharge prediction\n",
        "year_return = 100\n",
        "predict_value = linear_res.intercept + linear_res.slope * np.log(year_return)\n",
        "\n",
        "print('trimmed dataset predicted discharge for 1/{} years equals {:.0f} m^3/s'.format(year_return,predict_value))\n",
        "\n",
        "# year prediction\n",
        "future_value = 2000\n",
        "predict_year = np.exp((future_value - linear_res.intercept)/linear_res.slope)\n",
        "\n",
        "print('trimmed dataset predicted discharge for 1/{:.0f} years equals {} m^3/s'.format(predict_year,future_value))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_sPo7GKyU29"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}